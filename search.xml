<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[机器学习与数据挖掘中的相关术语]]></title>
    <url>%2F2018%2F05%2F09%2F%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B8%8E%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98%E4%B8%AD%E7%9A%84%E7%9B%B8%E5%85%B3%E6%9C%AF%E8%AF%AD%2F</url>
    <content type="text"><![CDATA[转自：机器学习算法与Python学习 Basis(基础)： MSE(Mean Square Error 均方误差)， LMS(LeastMean Square 最小均方)， LSM(Least Square Methods 最小二乘法)， MLE(MaximumLikelihood Estimation最大似然估计)， QP(Quadratic Programming 二次规划)， CP(Conditional Probability条件概率)， JP(Joint Probability 联合概率)， MP(Marginal Probability边缘概率)， Bayesian Formula(贝叶斯公式)， L1 /L2Regularization(L1/L2正则，以及更多的，现在比较火的L2.5正则等)， GD(GradientDescent 梯度下降)， SGD(Stochastic Gradient Descent 随机梯度下降)， Eigenvalue(特征值)， Eigenvector(特征向量)， Common Distribution(常见分布)： 1.1.1 Discrete Distribution(离散型分布)： BernoulliDistribution/Binomial(贝努利分布/二项分布)， Negative BinomialDistribution(负二项分布)， MultinomialDistribution(多项式分布)， Geometric Distribution(几何分布)， HypergeometricDistribution(超几何分布)， Poisson Distribution (泊松分布)。 1.1.2 Continuous Distribution (连续型分布)： UniformDistribution(均匀分布)， Normal Distribution /Guassian Distribution(正态分布/高斯分布)， ExponentialDistribution(指数分布)， Lognormal Distribution(对数正态分布)， GammaDistribution(Gamma分布)， Beta Distribution(Beta分布)， Dirichlet Distribution(狄利克雷分布)， Rayleigh Distribution(瑞利分布)， Cauchy Distribution(柯西分布)， Weibull Distribution (韦伯分布)。 1.1.3 Three Sampling Distribution(三大抽样分布)： Chi-squareDistribution(卡方分布)， t-distribution(t-distribution)， F-distribution(F-分布)。 Data Pre-processing(数据预处理)： Missing Value Imputation(缺失值填充)， Discretization(离散化)，Mapping(映射)， Normalization(归一化/标准化)。 Sampling(采样)： Simple Random Sampling(简单随机采样)， OfflineSampling(离线等可能K采样)， Online Sampling(在线等可能K采样)， Ratio-based Sampling(等比例随机采样)， Acceptance-RejectionSampling(接受-拒绝采样)， Importance Sampling(重要性采样)， MCMC(MarkovChain Monte Carlo 马尔科夫蒙特卡罗采样算法：Metropolis-Hasting&amp; Gibbs)。 Clustering(聚类)： Spectral-KMeans(谱聚类)， GMM-EM(混合高斯模型-期望最大化算法解决)， K-Pototypes，CLARANS(基于划分)， BIRCH(基于层次)， CURE(基于层次)， DBSCAN(基于密度)， CLIQUE(基于密度和基于网格)。 Classification&amp;Regression(分类&amp;回归)： LR(Linear Regression 线性回归)， LR(LogisticRegression逻辑回归)， SR(Softmax Regression 多分类逻辑回归)， GLM(GeneralizedLinear Model 广义线性模型)， RR(Ridge Regression 岭回归/L2正则最小二乘回归)， LASSO(Least Absolute Shrinkage andSelectionator Operator L1正则最小二乘回归)， RF(随机森林)， DT(DecisionTree决策树)， GBDT(Gradient BoostingDecision Tree 梯度下降决策树)， CART(ClassificationAnd Regression Tree 分类回归树)， KNN(K-Nearest Neighbor K近邻)， SVM(Support VectorMachine)， KF(KernelFunction 核函数PolynomialKernel Function 多项式核函、 Guassian KernelFunction 高斯核函数/Radial BasisFunction RBF径向基函数、 String KernelFunction 字符串核函数)、 NB(Naive Bayes 朴素贝叶斯)，BN(Bayesian Network/Bayesian Belief Network/ Belief Network 贝叶斯网络/贝叶斯信度网络/信念网络)， LDA(Linear Discriminant Analysis/FisherLinear Discriminant 线性判别分析/Fisher线性判别)， EL(Ensemble Learning集成学习Boosting，Bagging，Stacking)， AdaBoost(Adaptive Boosting 自适应增强)， MEM(MaximumEntropy Model最大熵模型)。 Effectiveness Evaluation(分类效果评估)： Confusion Matrix(混淆矩阵)， Precision(精确度)，Recall(召回率)， Accuracy(准确率)，F-score(F得分)， ROC Curve(ROC曲线)，AUC(AUC面积)， LiftCurve(Lift曲线) ，KS Curve(KS曲线)。 PGM(Probabilistic Graphical Models概率图模型)： BN(Bayesian Network/Bayesian Belief Network/ BeliefNetwork 贝叶斯网络/贝叶斯信度网络/信念网络)， MC(Markov Chain 马尔科夫链)， HMM(HiddenMarkov Model 马尔科夫模型)， MEMM(Maximum Entropy Markov Model 最大熵马尔科夫模型)， CRF(ConditionalRandom Field 条件随机场)， MRF(MarkovRandom Field 马尔科夫随机场)。 NN(Neural Network神经网络)： ANN(Artificial Neural Network 人工神经网络)， BP(Error BackPropagation 误差反向传播)。 DeepLearning Auto-encoder(自动编码器)， SAE(Stacked Auto-encoders堆叠自动编码器， Sparse Auto-encoders稀疏自动编码器、 Denoising Auto-encoders去噪自动编码器、 Contractive Auto-encoders 收缩自动编码器)， RBM(RestrictedBoltzmann Machine 受限玻尔兹曼机)， DBN(Deep Belief Network 深度信念网络)， CNN(ConvolutionalNeural Network 卷积神经网络)， Word2Vec(词向量学习模型)。 DimensionalityReduction(降维)： LDA LinearDiscriminant Analysis/Fisher Linear Discriminant 线性判别分析/Fisher线性判别， PCA(Principal Component Analysis 主成分分析)， ICA(IndependentComponent Analysis 独立成分分析)， SVD(Singular Value Decomposition 奇异值分解)， FA(FactorAnalysis 因子分析法)。 Text Mining(文本挖掘)： VSM(Vector Space Model向量空间模型)， Word2Vec(词向量学习模型)， TF(Term Frequency词频)， TF-IDF(Term Frequency-Inverse DocumentFrequency 词频-逆向文档频率)， MI(MutualInformation 互信息)， ECE(Expected Cross Entropy 期望交叉熵)， QEMI(二次信息熵)， IG(InformationGain 信息增益)， IGR(Information Gain Ratio 信息增益率)， Gini(基尼系数)， x2 Statistic(x2统计量)， TEW(TextEvidence Weight文本证据权)， OR(Odds Ratio 优势率)， N-Gram Model， LSA(Latent Semantic Analysis 潜在语义分析)， PLSA(ProbabilisticLatent Semantic Analysis 基于概率的潜在语义分析)， LDA(Latent DirichletAllocation 潜在狄利克雷模型)。 Association Mining(关联挖掘)： Apriori， FP-growth(Frequency Pattern Tree Growth 频繁模式树生长算法)， AprioriAll， Spade。 Recommendation Engine(推荐引擎)： DBR(Demographic-based Recommendation 基于人口统计学的推荐)， CBR(Context-basedRecommendation 基于内容的推荐)， CF(Collaborative Filtering协同过滤)， UCF(User-basedCollaborative Filtering Recommendation 基于用户的协同过滤推荐)， ICF(Item-basedCollaborative Filtering Recommendation 基于项目的协同过滤推荐)。 Similarity Measure&amp;Distance Measure(相似性与距离度量)： Euclidean Distance(欧式距离)， ManhattanDistance(曼哈顿距离)， Chebyshev Distance(切比雪夫距离)， MinkowskiDistance(闵可夫斯基距离)， Standardized Euclidean Distance(标准化欧氏距离)， MahalanobisDistance(马氏距离)， Cos(Cosine 余弦)， HammingDistance/Edit Distance(汉明距离/编辑距离)， JaccardDistance(杰卡德距离)， Correlation Coefficient Distance(相关系数距离)， InformationEntropy(信息熵)， KL(Kullback-Leibler Divergence KL散度/Relative Entropy 相对熵)。 Optimization(最优化)： 2.6.1 Non-constrainedOptimization(无约束优化)： Cyclic VariableMethods(变量轮换法)， Pattern Search Methods(模式搜索法)， VariableSimplex Methods(可变单纯形法)， Gradient Descent Methods(梯度下降法)， Newton Methods(牛顿法)， Quasi-NewtonMethods(拟牛顿法)， Conjugate Gradient Methods(共轭梯度法)。 2.6.2 ConstrainedOptimization(有约束优化)： Approximation Programming Methods(近似规划法)， FeasibleDirection Methods(可行方向法)， Penalty Function Methods(罚函数法)， Multiplier Methods(乘子法)。 Heuristic Algorithm(启发式算法)， SA(SimulatedAnnealing， 模拟退火算法)， GA(genetic algorithm遗传算法)。 Feature Selection(特征选择算法)： Mutual Information(互信息)， DocumentFrequence(文档频率)， Information Gain(信息增益)， Chi-squared Test(卡方检验)， Gini(基尼系数)。 Outlier Detection(异常点检测算法)： Statistic-based(基于统计)， Distance-based(基于距离)， Density-based(基于密度)， Clustering-based(基于聚类)。 Learning to Rank(基于学习的排序)： Pointwise：McRank； Pairwise：RankingSVM，RankNet，Frank，RankBoost； Listwise：AdaRank，SoftRank，LamdaMART。 Tool(工具)： MPI，Hadoop生态圈，Spark，BSP，Weka，Mahout，Scikit-learn，PyBrain… 以及一些具体的业务场景与case等。]]></content>
      <tags>
        <tag>机器学习</tag>
        <tag>数据挖掘</tag>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python3安装pymssql库时遇到的问题及解决方法]]></title>
    <url>%2F2018%2F05%2F05%2Fpython3%E5%AE%89%E8%A3%85pymssql%E5%BA%93%E6%97%B6%E9%81%87%E5%88%B0%E7%9A%84%E9%97%AE%E9%A2%98%E5%8F%8A%E8%A7%A3%E5%86%B3%E6%96%B9%E6%B3%95%2F</url>
    <content type="text"><![CDATA[今天在安装pymssql时出现了error:Microsoft Visual C++ 14.0 is required我的电脑里的确没有vc++14.0 这里提一下解决方法：1.首先访问点击这里,手动找到对应自己python版本的pymssql(cp后面是python版本) 我的python版本是3.6 AMD64 所以我下载图中红圈的那个 2.在cmd里执行：我下载的在E盘中pip install E:\pymssql-2.1.4.dev5-cp36-cp36m-win_amd64.whl OK successful！！！]]></content>
      <tags>
        <tag>python</tag>
        <tag>pymssql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[DDCTF 掀桌子题Write up]]></title>
    <url>%2F2018%2F05%2F02%2FDDCTF-%E6%8E%80%E6%A1%8C%E5%AD%90%E9%A2%98Write-up%2F</url>
    <content type="text"><![CDATA[作为一个CTF新手，第一次写write up还是有些惶恐的 这个题的题目是一个颜文字，然而…解决整个题的过程跟颜文字一点关系都没有。 刺不刺激，惊不惊喜 这个题的整体思路就是进制转换，先将16进制转换为10进制，再对128求余，剩下的结果转换为字符。 先仔细观察这个字符串的特点“d4e8e1f4a0f7e1f3a0e6e1f3f4a1a0d4e8e5a0e6ece1e7a0e9f3baa0c4c4c3d4c6fbb9e1e6b3e3b9e4b3b7b7e2b6b1e4b2b6b9e2b1b1b3b3b7e6b3b3b0e3b9b3b5e6fd”会发现字母最大就是f 是16进制没跑了 16进制一般是两个字符组成一个字节，拆解，转换成十进制之后会发现超出ASCII码范围，ASCII有0-127，所以脑洞大开 对128取余，之后再转换成字符。Bingo！！ 下面上代码： #coding:utf-8 import re import urllib list1=[] list2=[] s = &quot;d4e8e1f4a0f7e1f3a0e6e1f3f4a1a0d4e8e5a0e6ece1e7a0e9f3baa0c4c4c3d4c6fbb9b2b2e1e2b9b9b7b4e1b4 b7e3e4b3b2b2e3e6b4b3e2b5b0b6b1b0e6e1e5e1b5fd&quot; print len(s) result=re.sub(r&quot;(?&lt;=\w)(?=(?:\w\w)+$)&quot;,&quot; &quot;, s) print result urlencode_s=&quot;%&quot;+result.replace(&quot; &quot;,&quot;%&quot;) print urlencode_s hex_s = &quot;0x&quot;+result.replace(&quot; &quot;,&quot;0x&quot;) print hex_s print hex_s[-4:8] list_hex = [] for i in range(len(hex_s)): if((i+1)%4==0): print hex_s[(i-3):(i+1)] list1.append(hex_s[(i-3):(i+1)]) print i else: print i continue print list1 for i in list1: list2.append(int(i,16)) print list2 list3=[] for i in range(len(list2)): list3.append(chr(int(list2[i])-128)) s = &quot;&quot;.join(list3) print s PS：第一次参加CTF比赛，只做出来一道题。。。作为353名中的一份子我可能是最菜的 表情包奉上]]></content>
      <tags>
        <tag>CTF</tag>
        <tag>write up</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[域名重定向中的遇到的一些问题]]></title>
    <url>%2F2018%2F04%2F29%2F%E5%9F%9F%E5%90%8D%E9%87%8D%E5%AE%9A%E5%90%91%E4%B8%AD%E7%9A%84%E9%81%87%E5%88%B0%E7%9A%84%E4%B8%80%E4%BA%9B%E9%97%AE%E9%A2%98%2F</url>
    <content type="text"><![CDATA[很多人在解析自己的域名时都会遇到各种各样的问题，我在解析的时候就是跟着网上的例子一步一步来，诶，别人都能成功，我怎么也搞不成功，我这里遇到的问题是：server hold 域名在server hold状态下是无法解析成功的，且添加解析的时候不会给你提示，这个时候就需要自己去查询了，点击下面链接查询：whois万网查询 输入自己的域名查看信息，如果是处于server hold状态，我目前知道有两种可能： 1.域名没有实名认证 2.域名认证信息与身份证上信息不一致 没有实名认证的话就去实名认证一下，不过信息一定要和身份证上信息一致，不然虽然认证会成功，也有可能是server hold状态。 第2种情况可以通过域名服务–批量操作–批量过户至已经实名认证通过的信息模板去重新修改认证信息。重新认证信息无误成功后，通常情况注册局会在1-2个工作日恢复解析，建议耐心等待1-2个工作日之后再刷新查看域名状态。 我可是等了整整2天呐…┓(;´_｀)┏ 心累~~~]]></content>
      <tags>
        <tag>域名重定向</tag>
        <tag>域名解析</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[我的第一篇博客]]></title>
    <url>%2F2018%2F04%2F27%2F%E6%88%91%E7%9A%84%E7%AC%AC%E4%B8%80%E7%AF%87%E5%8D%9A%E5%AE%A2%2F</url>
    <content type="text"><![CDATA[给大家分享一首歌曲]]></content>
      <tags>
        <tag>learning</tag>
        <tag>why not?</tag>
      </tags>
  </entry>
</search>
